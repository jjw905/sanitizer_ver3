import os
import pickle
from typing import Dict, Any
from datetime import datetime

from utils.feature_extractor import FeatureExtractor
from utils.model_trainer import ModelTrainer
from config import DATA_SUFFICIENCY


class ModelManager:
    def __init__(self):
        self.trainer = ModelTrainer()
        self.feature_extractor = FeatureExtractor()
        self.model_loaded = False
        self.model_metadata = {}

    def is_model_available(self) -> bool:
        """í›ˆë ¨ëœ ëª¨ë¸ ì¡´ì¬ í™•ì¸ (300ê°œ ì´ìƒ ê¸°ì¤€)"""
        return (os.path.exists(self.trainer.model_path) and
                os.path.exists(self.trainer.scaler_path))

    def load_model(self) -> bool:
        """ëª¨ë¸ ë¡œë“œ"""
        if self.model_loaded:
            return True

        if not self.is_model_available():
            return False

        success = self.trainer.load_model()
        if success:
            self.model_loaded = True
            self._load_metadata()

        return success

    def _load_metadata(self):
        """ëª¨ë¸ ë©”íƒ€ë°ì´í„° ë¡œë“œ"""
        try:
            metadata_path = "models/model_metadata.pkl"
            if os.path.exists(metadata_path):
                with open(metadata_path, 'rb') as f:
                    self.model_metadata = pickle.load(f)
        except Exception as e:
            print(f"ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.model_metadata = {}

    def predict_file(self, file_path: str) -> Dict[str, Any]:
        """íŒŒì¼ ì•…ì„±ì½”ë“œ ì˜ˆì¸¡"""
        if not self.model_loaded:
            if not self.load_model():
                return {
                    "error": "ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € ëª¨ë¸ì„ í›ˆë ¨í•´ì£¼ì„¸ìš”.",
                    "prediction": "ì•Œ ìˆ˜ ì—†ìŒ",
                    "confidence": 0.0
                }

        return self.trainer.predict(file_path)

    def get_model_info(self) -> Dict[str, Any]:
        """ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
        info = {
            "model_available": self.is_model_available(),
            "model_loaded": self.model_loaded,
            "model_path": self.trainer.model_path,
            "scaler_path": self.trainer.scaler_path
        }

        if self.is_model_available():
            try:
                # íŒŒì¼ í¬ê¸° ê³„ì‚°
                model_size = os.path.getsize(self.trainer.model_path)
                scaler_size = os.path.getsize(self.trainer.scaler_path)

                info.update({
                    "model_size_mb": round(model_size / (1024 * 1024), 2),
                    "scaler_size_kb": round(scaler_size / 1024, 2),
                    "model_created": datetime.fromtimestamp(
                        os.path.getctime(self.trainer.model_path)
                    ).strftime('%Y-%m-%d %H:%M:%S')
                })

                # ë©”íƒ€ë°ì´í„° ì •ë³´ ì¶”ê°€
                if self.model_metadata:
                    info.update({
                        "training_samples": self.model_metadata.get('total_training_samples', 0),
                        "model_accuracy": self.model_metadata.get('accuracy', 0),
                        "training_date": self.model_metadata.get('training_date', 'Unknown'),
                        "model_version": self.model_metadata.get('version', '1.0'),
                        "update_count": self.model_metadata.get('update_count', 0),
                        "last_updated": self.model_metadata.get('last_updated', 'Never')
                    })

            except Exception as e:
                print(f"ëª¨ë¸ ì •ë³´ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")

        return info

    def update_model_with_new_data(self) -> bool:
        """ê¸°ì¡´ ëª¨ë¸ì„ ìƒˆë¡œìš´ ë°ì´í„°ë¡œ ì—…ë°ì´íŠ¸"""
        print("=== ëª¨ë¸ ì—…ë°ì´íŠ¸ ì‹œì‘ ===")

        try:
            # ìƒˆë¡œìš´ ë°ì´í„° ìˆ˜ì§‘
            print("ë‹¨ê³„ 1: ìƒˆë¡œìš´ ìƒ˜í”Œ ìˆ˜ì§‘ ì¤‘...")
            from utils.api_client import collect_additional_training_data
            new_sample_count = collect_additional_training_data(target_count=100)

            if new_sample_count == 0:
                print("âš ï¸ ìƒˆë¡œìš´ ìƒ˜í”Œì„ ìˆ˜ì§‘í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                return False

            # ëª¨ë¸ ì¬í›ˆë ¨ (ê¸°ì¡´ + ìƒˆ ë°ì´í„°)
            print("ë‹¨ê³„ 2: ëª¨ë¸ ì—…ë°ì´íŠ¸ í›ˆë ¨ ì¤‘...")
            success = self.trainer.train_model()

            if success:
                # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
                self._update_metadata(new_sample_count)
                print("âœ… ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ!")

                # ì—…ë°ì´íŠ¸ëœ ëª¨ë¸ ë‹¤ì‹œ ë¡œë“œ
                self.model_loaded = False
                self.load_model()
            else:
                print("âŒ ëª¨ë¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨")

            return success

        except Exception as e:
            print(f"âŒ ëª¨ë¸ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")
            return False

    def _update_metadata(self, new_sample_count: int):
        """ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸"""
        current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

        if not self.model_metadata:
            self.model_metadata = {
                'version': '1.0',
                'update_count': 0,
                'total_training_samples': 0
            }

        # ì—…ë°ì´íŠ¸ ì •ë³´ ê°±ì‹ 
        self.model_metadata.update({
            'last_updated': current_time,
            'update_count': self.model_metadata.get('update_count', 0) + 1,
            'total_training_samples': self.model_metadata.get('total_training_samples', 0) + new_sample_count,
            'version': f"1.{self.model_metadata.get('update_count', 0) + 1}"
        })

        # ë©”íƒ€ë°ì´í„° ì €ì¥
        try:
            metadata_path = "models/model_metadata.pkl"
            with open(metadata_path, 'wb') as f:
                pickle.dump(self.model_metadata, f)
        except Exception as e:
            print(f"ë©”íƒ€ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")

    def train_new_model(self) -> bool:
        """ìƒˆ ëª¨ë¸ í›ˆë ¨ (300ê°œ ì´ìƒ ë°ì´í„° ê¸°ì¤€)"""
        print("=== ìƒˆ ëª¨ë¸ í›ˆë ¨ ì‹œì‘ ===")

        # ê¸°ì¡´ ëª¨ë¸ ì–¸ë¡œë“œ
        self.model_loaded = False
        self.trainer.ensemble_model = None

        # ìƒˆ ëª¨ë¸ í›ˆë ¨
        success = self.trainer.train_model()

        if success:
            # ë©”íƒ€ë°ì´í„° ìƒì„±
            self._create_initial_metadata()

            # ìƒˆ ëª¨ë¸ ë¡œë“œ
            self.load_model()
            print("âœ… ìƒˆ ëª¨ë¸ í›ˆë ¨ ë° ë¡œë“œ ì™„ë£Œ!")
        else:
            print("âŒ ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨")

        return success

    def _create_initial_metadata(self):
        """ì´ˆê¸° ë©”íƒ€ë°ì´í„° ìƒì„±"""
        current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        data_status = self.get_training_data_status()

        self.model_metadata = {
            'version': '1.0',
            'training_date': current_time,
            'last_updated': current_time,
            'update_count': 0,
            'total_training_samples': data_status['total_samples'],
            'accuracy': 0.0,
            'model_type': 'ensemble'
        }

        # ë©”íƒ€ë°ì´í„° ì €ì¥
        try:
            metadata_path = "models/model_metadata.pkl"
            with open(metadata_path, 'wb') as f:
                pickle.dump(self.model_metadata, f)
        except Exception as e:
            print(f"ë©”íƒ€ë°ì´í„° ìƒì„± ì‹¤íŒ¨: {e}")

    def evaluate_current_model(self):
        """í˜„ì¬ ëª¨ë¸ í‰ê°€"""
        if not self.model_loaded:
            if not self.load_model():
                print("âŒ í‰ê°€í•  ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤")
                return

        self.trainer.evaluate_model()

    def get_training_data_status(self) -> Dict[str, int]:
        """í›ˆë ¨ ë°ì´í„° ìƒíƒœ í™•ì¸ (300ê°œ ì´ìƒ ê¸°ì¤€)"""
        malware_count = 0
        clean_count = 0

        if os.path.exists("sample/mecro"):
            malware_count = len([
                f for f in os.listdir("sample/mecro")
                if os.path.isfile(os.path.join("sample/mecro", f))
            ])

        if os.path.exists("sample/clear"):
            clean_count = len([
                f for f in os.listdir("sample/clear")
                if os.path.isfile(os.path.join("sample/clear", f))
            ])

        total_samples = malware_count + clean_count

        # ìƒˆë¡œìš´ ì¶©ë¶„ì„± ê¸°ì¤€ (300ê°œ ì´ìƒ)
        sufficient_data = (
                malware_count >= DATA_SUFFICIENCY['minimum_malware_samples'] and
                clean_count >= DATA_SUFFICIENCY['minimum_clean_samples'] and
                total_samples >= DATA_SUFFICIENCY['minimum_total_samples']
        )

        return {
            "malware_samples": malware_count,
            "clean_samples": clean_count,
            "total_samples": total_samples,
            "sufficient_data": sufficient_data,
            "recommended_total": DATA_SUFFICIENCY['recommended_training_size'],
            "sufficiency_percentage": round((total_samples / DATA_SUFFICIENCY['minimum_total_samples']) * 100, 1)
        }

    def batch_predict(self, file_paths: list) -> Dict[str, Dict]:
        """ë‹¤ì¤‘ íŒŒì¼ ì˜ˆì¸¡"""
        if not self.model_loaded:
            if not self.load_model():
                return {"error": "ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}

        results = {}

        for file_path in file_paths:
            try:
                file_name = os.path.basename(file_path)
                prediction = self.predict_file(file_path)
                results[file_name] = prediction
            except Exception as e:
                results[os.path.basename(file_path)] = {
                    "error": f"ì˜ˆì¸¡ ì‹¤íŒ¨: {str(e)}"
                }

        return results

    def get_model_performance_history(self) -> Dict[str, Any]:
        """ëª¨ë¸ ì„±ëŠ¥ íˆìŠ¤í† ë¦¬ ë°˜í™˜"""
        if not self.model_metadata:
            return {"error": "ë©”íƒ€ë°ì´í„° ì—†ìŒ"}

        return {
            "model_version": self.model_metadata.get('version', '1.0'),
            "update_count": self.model_metadata.get('update_count', 0),
            "training_date": self.model_metadata.get('training_date', 'Unknown'),
            "last_updated": self.model_metadata.get('last_updated', 'Never'),
            "total_training_samples": self.model_metadata.get('total_training_samples', 0),
            "current_accuracy": self.model_metadata.get('accuracy', 0),
            "model_type": self.model_metadata.get('model_type', 'ensemble')
        }

    def check_model_health(self) -> Dict[str, Any]:
        """ëª¨ë¸ ìƒíƒœ ê±´ê°•ì„± ì²´í¬"""
        health_status = {
            "model_exists": self.is_model_available(),
            "model_loadable": False,
            "data_sufficient": False,
            "performance_acceptable": False,
            "needs_update": False,
            "issues": [],
            "recommendations": []
        }

        # ëª¨ë¸ ë¡œë“œ ê°€ëŠ¥ì„± ì²´í¬
        if health_status["model_exists"]:
            health_status["model_loadable"] = self.load_model()

            if not health_status["model_loadable"]:
                health_status["issues"].append("ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")
                health_status["recommendations"].append("ëª¨ë¸ ì¬í›ˆë ¨ í•„ìš”")

        # ë°ì´í„° ì¶©ë¶„ì„± ì²´í¬
        data_status = self.get_training_data_status()
        health_status["data_sufficient"] = data_status["sufficient_data"]

        if not health_status["data_sufficient"]:
            health_status["issues"].append(
                f"í›ˆë ¨ ë°ì´í„° ë¶€ì¡± ({data_status['total_samples']}/{DATA_SUFFICIENCY['minimum_total_samples']})")
            health_status["recommendations"].append("ì¶”ê°€ ìƒ˜í”Œ ìˆ˜ì§‘ í•„ìš”")

        # ì„±ëŠ¥ ì²´í¬
        if self.model_metadata:
            accuracy = self.model_metadata.get('accuracy', 0)
            if accuracy > 0.85:
                health_status["performance_acceptable"] = True
            else:
                health_status["issues"].append(f"ëª¨ë¸ ì •í™•ë„ ë‚®ìŒ ({accuracy:.3f})")
                health_status["recommendations"].append("ëª¨ë¸ ì¬í›ˆë ¨ ë˜ëŠ” ë°ì´í„° í’ˆì§ˆ ê°œì„ ")

            # ì—…ë°ì´íŠ¸ í•„ìš”ì„± ì²´í¬ (30ì¼ ì´ìƒ)
            last_updated = self.model_metadata.get('last_updated', '')
            if last_updated:
                try:
                    from datetime import datetime, timedelta
                    last_update_date = datetime.strptime(last_updated, '%Y-%m-%d %H:%M:%S')
                    if datetime.now() - last_update_date > timedelta(days=30):
                        health_status["needs_update"] = True
                        health_status["recommendations"].append("30ì¼ ì´ìƒ ì—…ë°ì´íŠ¸ë˜ì§€ ì•ŠìŒ - ìµœì‹  ë°ì´í„°ë¡œ ì—…ë°ì´íŠ¸ ê¶Œì¥")
                except:
                    pass

        # ì „ì²´ ìƒíƒœ í‰ê°€
        if health_status["model_exists"] and health_status["model_loadable"] and health_status["data_sufficient"]:
            health_status["overall_status"] = "ì–‘í˜¸"
        elif health_status["model_exists"] and health_status["model_loadable"]:
            health_status["overall_status"] = "ë³´í†µ"
        else:
            health_status["overall_status"] = "ë¶ˆëŸ‰"

        return health_status


# ì „ì—­ ëª¨ë¸ ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤
model_manager = ModelManager()


def get_model_manager() -> ModelManager:
    """ëª¨ë¸ ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    return model_manager


if __name__ == "__main__":
    # ê°„ë‹¨ í…ŒìŠ¤íŠ¸
    manager = ModelManager()

    print("=== ëª¨ë¸ ê´€ë¦¬ì í…ŒìŠ¤íŠ¸ ===")

    # ë°ì´í„° ìƒíƒœ í™•ì¸
    data_status = manager.get_training_data_status()
    print(f"í›ˆë ¨ ë°ì´í„°: ì•…ì„± {data_status['malware_samples']}ê°œ, ì •ìƒ {data_status['clean_samples']}ê°œ")
    print(f"ì¶©ë¶„ì„±: {data_status['sufficiency_percentage']}% ({'ì¶©ë¶„' if data_status['sufficient_data'] else 'ë¶€ì¡±'})")

    # ëª¨ë¸ ìƒíƒœ í™•ì¸
    if manager.is_model_available():
        print("âœ… ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥")
        if manager.load_model():
            print("âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
        else:
            print("âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")
    else:
        print("âŒ í›ˆë ¨ëœ ëª¨ë¸ ì—†ìŒ")
        if data_status['sufficient_data']:
            print("ğŸ’¡ ì¶©ë¶„í•œ ë°ì´í„° ìˆìŒ - ëª¨ë¸ í›ˆë ¨ ê°€ëŠ¥")
        else:
            print(f"ğŸ’¡ {DATA_SUFFICIENCY['minimum_total_samples'] - data_status['total_samples']}ê°œ ìƒ˜í”Œ ë” í•„ìš”")